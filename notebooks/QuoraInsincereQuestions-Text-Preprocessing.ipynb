{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quora Insincere Questions Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problem Statement: </b>\n",
    "An existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.\n",
    "\n",
    "Quora is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.\n",
    "\n",
    "The aim of the problem is to detect toxic and misleading content in given a question.\n",
    "\n",
    "An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
    "\n",
    "<ul>\n",
    "    <li>Has a non-neutral tone.\n",
    "        <ul>\n",
    "            <li>Has an exaggerated tone to underscore a point about a group of people.</li>\n",
    "            <li>Is rhetorical and meant to imply a statement about a group of people.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Is disparaging or inflammatory.\n",
    "        <ul>\n",
    "            <li>Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype.</li>\n",
    "            <li>Makes disparaging attacks/insults against a specific person or group of people.</li>\n",
    "            <li>Based on an outlandish premise about a group of people.</li>\n",
    "            <li>Disparages against a characteristic that is not fixable and not measurable.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Isn't grounded in reality.\n",
    "        <ul>\n",
    "            <li>Based on false information, or contains absurd assumptions</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers.</li>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "Source :: https://www.kaggle.com/c/quora-insincere-questions-classification/overview/description\n",
    "<br/><br/>\n",
    "\n",
    "<b>Evaluation Metric: F1 Score</b>\n",
    "\n",
    "F1-Score = 2 x (precision x recall) / (precision + recall)\n",
    "\n",
    "<b>Precision:</b> The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "<b>Recall:</b> The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataset Description</b>\n",
    "\n",
    "The dataset is divided into two parts<br/>\n",
    "<ol>\n",
    "    <li>Train</li>\n",
    "    <li>Test</li>\n",
    "</ol>\n",
    "\n",
    "<b>1. Train </b>\n",
    "\n",
    "Number of rows: 1.31 Million records.<br/>\n",
    "Number of columns: 3 <br/>\n",
    "\n",
    "Columns:\n",
    "<ul>\n",
    "    <li><b>qid: </b> Question Id</li>\n",
    "    <li><b>question_text: </b> Question text.</li>\n",
    "    <li><b>target: </b> target whether the question is sincere or not. if question is insincere then target is 1 else 0.</li>    \n",
    "</ul>\n",
    "\n",
    "<b>1. Test </b>\n",
    "\n",
    "Number of rows: 376000 records.<br/>\n",
    "Number of columns: 2 <br/>\n",
    "\n",
    "Columns:\n",
    "<ul>\n",
    "    <li><b>qid: </b> Question Id</li>\n",
    "    <li><b>question_text: </b> Question text.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import operator \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def load_embed(file):    \n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting GloVe embedding\n",
      "CPU times: user 3min 38s, sys: 6.83 s, total: 3min 45s\n",
      "Wall time: 10min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Extracting GloVe embedding\")\n",
    "embed_glove = load_embed('glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word.strip()] = embeddings_index[word.strip()]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.58 s, sys: 400 ms, total: 9.98 s\n",
      "Wall time: 9.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = build_vocab(train_df['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 33.02% of vocab\n",
      "Found embeddings for  88.15% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India?', 16384),\n",
       " ('it?', 12900),\n",
       " (\"What's\", 12425),\n",
       " ('do?', 8753),\n",
       " ('life?', 7753),\n",
       " ('you?', 6295),\n",
       " ('me?', 6202),\n",
       " ('them?', 6140),\n",
       " ('time?', 5716),\n",
       " ('world?', 5386)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b><br/>\n",
    "We can only get 33% of vocab and 88.15% of all text word vectors.\n",
    "As we can see from the above cell lot of text processing needs to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets check by lower casing the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lowered_question'] = train_df['question_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_low = build_vocab(train_df['lowered_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 27.38% of vocab\n",
      "Found embeddings for  87.87% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_low, embed_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b><br/>\n",
    "We can see that code coverage has now decreased on vocab and slightly increase for all text.\n",
    "From the above we can note that lower casing decreased total vocab coverage so we need to lowercase only words which does not have embedding for normal word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lower(embedding, vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:  \n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "    print(f\"Added {count} words to embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Added 14725 words to embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "add_lower(embed_glove, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 33.28% of vocab\n",
      "Found embeddings for  88.16% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('fight,', 451),\n",
       "  ('line?', 451),\n",
       "  ('sites?', 451),\n",
       "  ('France?', 451),\n",
       "  (\"women's\", 450),\n",
       "  ('loss?', 450),\n",
       "  ('teacher?', 449),\n",
       "  ('working?', 449),\n",
       "  ('examples?', 449),\n",
       "  ('mother?', 448)],\n",
       " [('from?', 1369),\n",
       "  ('others?', 1356),\n",
       "  ('Mumbai?', 1347),\n",
       "  ('society?', 1341),\n",
       "  ('use?', 1334),\n",
       "  ('number?', 1332),\n",
       "  ('with?', 1321),\n",
       "  ('back?', 1319),\n",
       "  ('me,', 1310),\n",
       "  ('friends?', 1306)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[500:510], oov_glove[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b><br/>\n",
    "Now the code coverage is slightly increased from 33.02% to 33.28%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/nealrs/96342d8231b75cf4bb82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cList = {\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"I'd\": \"I would\",\n",
    "  \"I'd've\": \"I would have\",\n",
    "  \"I'll\": \"I will\",\n",
    "  \"I'll've\": \"I will have\",\n",
    "  \"I'm\": \"I am\",\n",
    "  \"I've\": \"I have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you you will\",\n",
    "  \"you'll've\": \"you you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known contractions available in embedding\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"can't\",\n",
       " \"'cause\",\n",
       " \"didn't\",\n",
       " \"doesn't\",\n",
       " \"don't\",\n",
       " \"I'd\",\n",
       " \"I'll\",\n",
       " \"I'm\",\n",
       " \"I've\",\n",
       " \"it's\",\n",
       " \"ma'am\",\n",
       " \"o'clock\",\n",
       " \"that's\",\n",
       " \"you'll\",\n",
       " \"you're\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_contractions = []\n",
    "for k in cList.keys():\n",
    "    if k in embed_glove:\n",
    "        known_contractions.append(k)\n",
    "print('Known contractions available in embedding')\n",
    "known_contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove known contractions from cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in known_contractions:\n",
    "    del cList[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_re = re.compile('(%s)' % '|'.join(cList.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return cList[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you have, am not'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expandContractions(\"you've, ain't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = train_df['lowered_question'].apply(lambda x: expandContractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    how did quebec nationalists see their province...\n",
       "1    do you have an adopted dog, how would you enco...\n",
       "2    why does velocity affect time? does velocity a...\n",
       "3    how did otto von guericke used the magdeburg h...\n",
       "4    can i convert montra helicon d to a mountain b...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 39.8 ms, total: 11.6 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = build_vocab(train_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 30.66% of vocab\n",
      "Found embeddings for  88.43% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('india?', 16394),\n",
       " ('it?', 13158),\n",
       " ('do?', 8766),\n",
       " ('life?', 7791),\n",
       " ('why?', 7369),\n",
       " ('you?', 6314),\n",
       " ('me?', 6241),\n",
       " ('them?', 6141),\n",
       " ('time?', 5742),\n",
       " ('world?', 5525)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', \n",
    "          '*', '+', '\\\\', '•',  '~', '@', '£', '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', \n",
    "          '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢',\n",
    "          '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕',\n",
    "          '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', \n",
    "          '∞','∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', \n",
    "          'ï', 'Ø', '¹', '≤', '‡', '√', '∞', 'θ', '÷', 'α', '•', 'à', '−', 'β', '∅', '³', 'π', '‘','₹', \n",
    "          '´', \"'\", '°', '£', '€', '×', '™','√','²','—–','&','…', \"’\", \"“\", \"”\", \"#\", \"{\", \"|\", \"}\", \"~\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known punctuations\n",
      ", . \" : ) ( - ! ? | ; ' $ & / [ ] > % = # * + \\ ~ @ _ { } ^ ` < ' & # { | } ~\n",
      "**************************************************\n",
      "Unknown punctuations\n",
      "• £ · © ® → ° € ™ › ♥ ← × § ″ ′ Â █ ½ à … “ ★ ” – ● â ► − ¢ ² ¬ ░ ¶ ↑ ± ¿ ▾ ═ ¦ ║ ― ¥ ▓ — ‹ ─ ▒ ： ¼ ⊕ ▼ ▪ † ■ ’ ▀ ¨ ▄ ♫ ☆ é ¯ ♦ ¤ ▲ è ¸ ¾ Ã ⋅ ‘ ∞ ∙ ） ↓ 、 │ （ » ， ♪ ╩ ╚ ³ ・ ╦ ╣ ╔ ╗ ▬ ❤ ï Ø ¹ ≤ ‡ √ ∞ θ ÷ α • à − β ∅ ³ π ‘ ₹ ´ ° £ € × ™ √ ² —– … ’ “ ”\n"
     ]
    }
   ],
   "source": [
    "unknown_punctuations = []\n",
    "known_puncts = []\n",
    "for p in puncts:\n",
    "    if p not in embed_glove:\n",
    "        unknown_punctuations.append(p)\n",
    "    else:\n",
    "        known_puncts.append(p)\n",
    "print('Known punctuations')\n",
    "print(' '.join(known_puncts))\n",
    "print('*'*50)\n",
    "print('Unknown punctuations')\n",
    "print(' '.join(unknown_punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for p in unknown_punctuations:\n",
    "        text = text.replace(p, ' ')\n",
    "    for p in known_puncts:\n",
    "        text = text.replace(p, ' ' + p + ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi ,   xyz'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuations('Hi,® xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['final_cleaned_text'] = train_df['cleaned_text'].apply(lambda x: remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 51.7 ms, total: 10.8 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = build_vocab(train_df['final_cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 69.57% of vocab\n",
      "Found embeddings for  99.58% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab, embed_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b><br/>\n",
    "Now the code coverage is slightly increased from 33.28% to 69.57% and covers 99.58% of all text. So removing punctuations increased vocab coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look into words that are not in our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quorans', 858),\n",
       " ('brexit', 524),\n",
       " ('cryptocurrencies', 499),\n",
       " ('redmi', 383),\n",
       " ('coinbase', 149),\n",
       " ('oneplus', 139),\n",
       " ('uceed', 123),\n",
       " ('demonetisation', 115),\n",
       " ('bhakts', 115),\n",
       " ('upwork', 111)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 most occured words which are not present in vocab\n",
    "oov_glove[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5dcv', 1),\n",
       " ('pakkstani', 1),\n",
       " ('venuas', 1),\n",
       " ('ohmagawd', 1),\n",
       " ('savegely', 1),\n",
       " ('1500mph', 1),\n",
       " ('anizara', 1),\n",
       " ('4afsb', 1),\n",
       " ('tepelene', 1),\n",
       " ('calead', 1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Quorans doesn't exists in our vocab so lets check if quoran exists\n",
    "'quoran' in embed_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets correct these spelling mistakes and maintain a dict of mapping\n",
    "# load the spell_corrections.json\n",
    "with open('spell_corrections.json', 'r') as f:\n",
    "    spell_corrections = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spellings(text):\n",
    "    for k in spell_corrections.keys():\n",
    "        text = text.replace(k, spell_corrections[k])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numerics(text):\n",
    "    return re.sub('[^A-Za-z]+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['final_cleaned_text'] = train_df['final_cleaned_text'].apply(lambda x: correct_spellings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['final_cleaned_text'] = train_df['final_cleaned_text'].apply(lambda x: remove_numerics(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 11.9 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = build_vocab(train_df['final_cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 71.59% of vocab\n",
      "Found embeddings for  99.61% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('redmi', 387),\n",
       " ('coinbase', 149),\n",
       " ('oneplus', 146),\n",
       " ('uceed', 124),\n",
       " ('bhakts', 115),\n",
       " ('upwork', 111),\n",
       " ('machedo', 108),\n",
       " ('adityanath', 106),\n",
       " ('boruto', 102),\n",
       " ('alshamsi', 92),\n",
       " ('dceu', 90),\n",
       " ('litecoin', 87),\n",
       " ('iiest', 86),\n",
       " ('unacademy', 86),\n",
       " ('zerodha', 80),\n",
       " ('tensorflow', 74),\n",
       " ('doklam', 70),\n",
       " ('kavalireddi', 69),\n",
       " ('muoet', 66),\n",
       " ('nicmar', 62)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bandhup', 1),\n",
       " ('seago', 1),\n",
       " ('bhashani', 1),\n",
       " ('ingredio', 1),\n",
       " ('dcv', 1),\n",
       " ('ohmagawd', 1),\n",
       " ('savegely', 1),\n",
       " ('anizara', 1),\n",
       " ('tepelene', 1),\n",
       " ('calead', 1)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sent(t):\n",
    "    quorans_sentence = []\n",
    "    for s in train_df['final_cleaned_text']:\n",
    "        if t in s:\n",
    "            quorans_sentence.append(s)\n",
    "        if len(quorans_sentence) > 5:\n",
    "            break\n",
    "    return quorans_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['which is best changer for redmi note ',\n",
       " 'will the redmi note pro indian model work in the us ',\n",
       " 'when redmi note get miui update ',\n",
       " 'what are some android apps for split screen multi tasking available for redmi note marshmallow ',\n",
       " 'what are the fascinating things about redmi a ',\n",
       " 'what is the best in redmi note ']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_sent('redmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>lowered_question</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>how did quebec nationalists see their province...</td>\n",
       "      <td>how did quebec nationalists see their province...</td>\n",
       "      <td>how did quebec nationalists see their province...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>do you have an adopted dog, how would you enco...</td>\n",
       "      <td>do you have an adopted dog, how would you enco...</td>\n",
       "      <td>do you have an adopted dog how would you encou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>why does velocity affect time? does velocity a...</td>\n",
       "      <td>why does velocity affect time? does velocity a...</td>\n",
       "      <td>why does velocity affect time does velocity af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>how did otto von guericke used the magdeburg h...</td>\n",
       "      <td>how did otto von guericke used the magdeburg h...</td>\n",
       "      <td>how did otto von guericke used the magdeburg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>can i convert montra helicon d to a mountain b...</td>\n",
       "      <td>can i convert montra helicon d to a mountain b...</td>\n",
       "      <td>can i convert montra helicon d to a mountain b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target                                   lowered_question  \\\n",
       "0       0  how did quebec nationalists see their province...   \n",
       "1       0  do you have an adopted dog, how would you enco...   \n",
       "2       0  why does velocity affect time? does velocity a...   \n",
       "3       0  how did otto von guericke used the magdeburg h...   \n",
       "4       0  can i convert montra helicon d to a mountain b...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  how did quebec nationalists see their province...   \n",
       "1  do you have an adopted dog, how would you enco...   \n",
       "2  why does velocity affect time? does velocity a...   \n",
       "3  how did otto von guericke used the magdeburg h...   \n",
       "4  can i convert montra helicon d to a mountain b...   \n",
       "\n",
       "                                  final_cleaned_text  \n",
       "0  how did quebec nationalists see their province...  \n",
       "1  do you have an adopted dog how would you encou...  \n",
       "2  why does velocity affect time does velocity af...  \n",
       "3  how did otto von guericke used the magdeburg h...  \n",
       "4  can i convert montra helicon d to a mountain b...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>target</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>0</td>\n",
       "      <td>how did quebec nationalists see their province...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>0</td>\n",
       "      <td>do you have an adopted dog how would you encou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>0</td>\n",
       "      <td>why does velocity affect time does velocity af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>0</td>\n",
       "      <td>how did otto von guericke used the magdeburg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>0</td>\n",
       "      <td>can i convert montra helicon d to a mountain b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  target  \\\n",
       "0  00002165364db923c7e6       0   \n",
       "1  000032939017120e6e44       0   \n",
       "2  0000412ca6e4628ce2cf       0   \n",
       "3  000042bf85aa498cd78e       0   \n",
       "4  0000455dfa3e01eae3af       0   \n",
       "\n",
       "                                  final_cleaned_text  \n",
       "0  how did quebec nationalists see their province...  \n",
       "1  do you have an adopted dog how would you encou...  \n",
       "2  why does velocity affect time does velocity af...  \n",
       "3  how did otto von guericke used the magdeburg h...  \n",
       "4  can i convert montra helicon d to a mountain b...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['qid', 'target', 'final_cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['qid', 'target', 'final_cleaned_text']].to_csv('final_cleaned_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
