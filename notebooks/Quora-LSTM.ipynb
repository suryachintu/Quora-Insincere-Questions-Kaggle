{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cM_joh6RmDFq",
    "outputId": "0087676e-e144-4915-a337-f123b0246c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrGfQN-1mObd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import operator \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyzAwcvFmcSe"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'drive/My Drive/final_cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "HkQV6j6onHoH",
    "outputId": "4161e33b-8e82-416e-e600-f62643552781"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>target</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>0</td>\n",
       "      <td>how did quebec nationalists see their province...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>0</td>\n",
       "      <td>do you have an adopted dog how would you encou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>0</td>\n",
       "      <td>why does velocity affect time does velocity af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>0</td>\n",
       "      <td>how did otto von guericke used the magdeburg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>0</td>\n",
       "      <td>can i convert montra helicon d to a mountain b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  ...                                 final_cleaned_text\n",
       "0  00002165364db923c7e6  ...  how did quebec nationalists see their province...\n",
       "1  000032939017120e6e44  ...  do you have an adopted dog how would you encou...\n",
       "2  0000412ca6e4628ce2cf  ...  why does velocity affect time does velocity af...\n",
       "3  000042bf85aa498cd78e  ...  how did otto von guericke used the magdeburg h...\n",
       "4  0000455dfa3e01eae3af  ...  can i convert montra helicon d to a mountain b...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esC7olXNnk-1"
   },
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JPpOrW4aoLxi",
    "outputId": "9b5f5d2a-07d4-4035-b37d-093e61bcc49b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FvHFjLgoiR6"
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 60\n",
    "VALIDATION_SPLIT = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "mw14-B0psSba",
    "outputId": "1b24b0a5-9397-4368-f3ca-e13622824bdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    how did quebec nationalists see their province...\n",
       "1    do you have an adopted dog how would you encou...\n",
       "2    why does velocity affect time does velocity af...\n",
       "3    how did otto von guericke used the magdeburg h...\n",
       "4    can i convert montra helicon d to a mountain b...\n",
       "Name: final_cleaned_text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['final_cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9PzddnL8oOKR",
    "outputId": "da82bca7-9281-45e4-ce9a-75f65c5cf2e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 178708 unique tokens.\n",
      "Shape of data tensor: (1306122, 60)\n",
      "Shape of label tensor: (1306122,)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='OOV_TOKEN')\n",
    "tokenizer.fit_on_texts(train_df['final_cleaned_text'].values)\n",
    "sequences = tokenizer.texts_to_sequences(train_df['final_cleaned_text'].values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "labels = train_df['target'].values\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(train_df.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x05XyvV_psvT"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def load_embed(file):    \n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wZ2trxy7pxp7",
    "outputId": "4d7ef6bf-d39d-4bcd-c449-d54065fb4738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting GloVe embedding\n",
      "CPU times: user 2min 37s, sys: 4.27 s, total: 2min 42s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Extracting GloVe embedding\")\n",
    "embed_glove = load_embed('glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1v6_hg6_p5cn",
    "outputId": "a9aae714-479f-4346-ad6a-92a965650104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196017\n"
     ]
    }
   ],
   "source": [
    "print(len(embed_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDqa_LfYq15f"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RUcDhAtq-Vz"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tZghcyiVqr_S",
    "outputId": "c844052a-7a28-417f-c877-11c4d9dc4904"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178708/178708 [00:00<00:00, 426164.55it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embed_glove.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ZNARf2Q52K8Y",
    "outputId": "0a4fc8b0-0f60-40d7-cbc1-aac04a3c45c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGuFekL92vgo"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Dropout, Bidirectional\n",
    "from keras.models import Model, Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXW2QqdL5CmI"
   },
   "outputs": [],
   "source": [
    "# code :: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-\n",
    "# and-recall-for-a-keras-model\n",
    "def get_f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Cyclic Learning Rate:</b>\n",
    "Orginal blog post :: https://www.fast.ai/2018/08/10/fastai-diu-imagenet/\n",
    "<br/><br/>\n",
    "Keras implementaion Source code :: https://www.kaggle.com/dude431/keras-cyclic-lr\n",
    "<br/><br/>\n",
    "<b>Other references</b>\n",
    "https://towardsdatascience.com/adaptive-and-cyclical-learning-rates-using-pytorch-2bf904d18dee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqPRg8-r4IaO"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    def __init__(\n",
    "            self,base_lr=0.001,\n",
    "            max_lr=0.006,step_size=2000.,\n",
    "            mode='triangular',gamma=1.,\n",
    "            scale_fn=None,scale_mode='cycle'):\n",
    "        \n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2','exp_range']:\n",
    "            raise KeyError(\"mode must be one of 'triangular', \"\n",
    "                           \"'triangular2', or 'exp_range'\")\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1 / (2.**(x - 1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma ** x\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        if new_base_lr is not None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr is not None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size is not None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
    "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
    "                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
    "                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "\n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "        self.history.setdefault(\n",
    "            'lr', []).append(\n",
    "            K.get_value(\n",
    "                self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>References</b><br/>\n",
    "https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/\n",
    "<br/><br/>\n",
    "<b>Keras implementation</b><br/>\n",
    "https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Attention Layer</b>\n",
    "\n",
    "Lets take a look at previous coventions like CountVectorizer and TFIDF Vectorizer to extract features from text, both worked well but they have their own disadvantages in case of CountVectorizer or Bag of Words representation it only takes into account the number of times the word occured in the document thus giving more importance to a word which occured more times. TFIDF solves this issue, tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word that means it gives higher weightage to the words that occur very rare and low to more frequently occured thus TFIDF works best in most of the cases than norma bag of words but the major disadvantage is they don't consider the sequence thats where LSTM's/GRU/RNN came to place and performed very well by considering the sequence but we loose ability to give higher wieghtage to more important words. So what if we have LSTM'S/RNN/GRU have a capability to give much importance to words that are important thats where <b>Attention</b> mechanism is introduced. More details on this paper (https://arxiv.org/abs/1706.03762) and https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='s1.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='s2.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "e_{t} & = \\tanh(W_a*h_t + b_a) \\\\\n",
    "\\alpha_{t} & = exp^{e_t} /(\\sum_{k=1}^t exp^{e_t}) \\\\ \n",
    "c & = \\sum_{k=1}^t \\alpha_k * h_k \\\\ \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e_t :: Output at state t. <br/>\n",
    "alpha_t :: Softmax(e_t).  <br/>\n",
    "c_t :: alpha_t * h_t.  <br/>\n",
    "c :: sum(c_t).  <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPJuMOAh1l0b"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        # calculate e_t\n",
    "        et = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            et += self.b\n",
    "        \n",
    "        # apply tanh activation\n",
    "        et = K.tanh(eij)\n",
    "        \n",
    "        # calculate exp of e_t\n",
    "        a = K.exp(et)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        \n",
    "        # Apply softmax\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        # calculate sum\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "kGEp_VvL2Z1s",
    "outputId": "a06b1879-62e3-43ad-d2de-df85c3f05880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 60, 300)           53612700  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 60, 128)           186880    \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 128)               188       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 53,810,137\n",
      "Trainable params: 197,437\n",
      "Non-trainable params: 53,612,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.25, recurrent_dropout=0.25, return_sequences=True)))\n",
    "model.add(Attention(MAX_SEQUENCE_LENGTH))\n",
    "model.add(Dense(64, activation='elu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[get_f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdcAL_Z55_Tp"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8NCYjHh5L3Z"
   },
   "outputs": [],
   "source": [
    "clr = CyclicLR(base_lr=0.001, max_lr=0.009,step_size=400, mode='triangular', gamma=0.99994)\n",
    "filepath=\"weights-improvement.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_get_f1', verbose=1, \\\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, clr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iM7lGykJcVsD",
    "outputId": "40515c5c-099a-4217-e184-64b618090e24",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 640000 samples, validate on 274286 samples\n",
      "Epoch 1/25\n",
      "640000/640000 [==============================] - 114s 178us/step - loss: 0.1807 - get_f1: 0.3338 - val_loss: 0.1169 - val_get_f1: 0.5577\n",
      "\n",
      "Epoch 00001: val_get_f1 improved from -inf to 0.55773, saving model to weights-improvement.hdf5\n",
      "Epoch 2/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.1148 - get_f1: 0.5723 - val_loss: 0.1112 - val_get_f1: 0.5754\n",
      "\n",
      "Epoch 00002: val_get_f1 improved from 0.55773 to 0.57539, saving model to weights-improvement.hdf5\n",
      "Epoch 3/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.1078 - get_f1: 0.6113 - val_loss: 0.1045 - val_get_f1: 0.6424\n",
      "\n",
      "Epoch 00003: val_get_f1 improved from 0.57539 to 0.64237, saving model to weights-improvement.hdf5\n",
      "Epoch 4/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.1025 - get_f1: 0.6389 - val_loss: 0.1026 - val_get_f1: 0.6515\n",
      "\n",
      "Epoch 00004: val_get_f1 improved from 0.64237 to 0.65152, saving model to weights-improvement.hdf5\n",
      "Epoch 5/25\n",
      "640000/640000 [==============================] - 112s 174us/step - loss: 0.0979 - get_f1: 0.6563 - val_loss: 0.1020 - val_get_f1: 0.6548\n",
      "\n",
      "Epoch 00005: val_get_f1 improved from 0.65152 to 0.65482, saving model to weights-improvement.hdf5\n",
      "Epoch 6/25\n",
      "640000/640000 [==============================] - 112s 174us/step - loss: 0.0958 - get_f1: 0.6656 - val_loss: 0.1023 - val_get_f1: 0.6523\n",
      "\n",
      "Epoch 00006: val_get_f1 did not improve from 0.65482\n",
      "Epoch 7/25\n",
      "640000/640000 [==============================] - 112s 175us/step - loss: 0.0965 - get_f1: 0.6635 - val_loss: 0.1054 - val_get_f1: 0.6672\n",
      "\n",
      "Epoch 00007: val_get_f1 improved from 0.65482 to 0.66718, saving model to weights-improvement.hdf5\n",
      "Epoch 8/25\n",
      "640000/640000 [==============================] - 112s 175us/step - loss: 0.0963 - get_f1: 0.6632 - val_loss: 0.1070 - val_get_f1: 0.6170\n",
      "\n",
      "Epoch 00008: val_get_f1 did not improve from 0.66718\n",
      "Epoch 9/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0934 - get_f1: 0.6731 - val_loss: 0.1041 - val_get_f1: 0.6697\n",
      "\n",
      "Epoch 00009: val_get_f1 improved from 0.66718 to 0.66966, saving model to weights-improvement.hdf5\n",
      "Epoch 10/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0890 - get_f1: 0.6920 - val_loss: 0.1032 - val_get_f1: 0.6693\n",
      "\n",
      "Epoch 00010: val_get_f1 did not improve from 0.66966\n",
      "Epoch 11/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0864 - get_f1: 0.7012 - val_loss: 0.1058 - val_get_f1: 0.6682\n",
      "\n",
      "Epoch 00011: val_get_f1 did not improve from 0.66966\n",
      "Epoch 12/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0878 - get_f1: 0.6972 - val_loss: 0.1031 - val_get_f1: 0.6648\n",
      "\n",
      "Epoch 00012: val_get_f1 did not improve from 0.66966\n",
      "Epoch 13/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0892 - get_f1: 0.6906 - val_loss: 0.1027 - val_get_f1: 0.6598\n",
      "\n",
      "Epoch 00013: val_get_f1 did not improve from 0.66966\n",
      "Epoch 14/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0877 - get_f1: 0.6959 - val_loss: 0.1049 - val_get_f1: 0.6683\n",
      "\n",
      "Epoch 00014: val_get_f1 did not improve from 0.66966\n",
      "Epoch 15/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0838 - get_f1: 0.7138 - val_loss: 0.1058 - val_get_f1: 0.6694\n",
      "\n",
      "Epoch 00015: val_get_f1 did not improve from 0.66966\n",
      "Epoch 16/25\n",
      "640000/640000 [==============================] - 112s 174us/step - loss: 0.0806 - get_f1: 0.7240 - val_loss: 0.1083 - val_get_f1: 0.6648\n",
      "\n",
      "Epoch 00016: val_get_f1 did not improve from 0.66966\n",
      "Epoch 17/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0822 - get_f1: 0.7175 - val_loss: 0.1081 - val_get_f1: 0.6684\n",
      "\n",
      "Epoch 00017: val_get_f1 did not improve from 0.66966\n",
      "Epoch 18/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0846 - get_f1: 0.7071 - val_loss: 0.1070 - val_get_f1: 0.6677\n",
      "\n",
      "Epoch 00018: val_get_f1 did not improve from 0.66966\n",
      "Epoch 19/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0841 - get_f1: 0.7108 - val_loss: 0.1057 - val_get_f1: 0.6625\n",
      "\n",
      "Epoch 00019: val_get_f1 did not improve from 0.66966\n",
      "Epoch 20/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0808 - get_f1: 0.7227 - val_loss: 0.1054 - val_get_f1: 0.6671\n",
      "\n",
      "Epoch 00020: val_get_f1 did not improve from 0.66966\n",
      "Epoch 21/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0776 - get_f1: 0.7355 - val_loss: 0.1098 - val_get_f1: 0.6625\n",
      "\n",
      "Epoch 00021: val_get_f1 did not improve from 0.66966\n",
      "Epoch 22/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0787 - get_f1: 0.7314 - val_loss: 0.1060 - val_get_f1: 0.6469\n",
      "\n",
      "Epoch 00022: val_get_f1 did not improve from 0.66966\n",
      "Epoch 23/25\n",
      "640000/640000 [==============================] - 112s 174us/step - loss: 0.0816 - get_f1: 0.7185 - val_loss: 0.1088 - val_get_f1: 0.6655\n",
      "\n",
      "Epoch 00023: val_get_f1 did not improve from 0.66966\n",
      "Epoch 24/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0815 - get_f1: 0.7200 - val_loss: 0.1073 - val_get_f1: 0.6635\n",
      "\n",
      "Epoch 00024: val_get_f1 did not improve from 0.66966\n",
      "Epoch 25/25\n",
      "640000/640000 [==============================] - 111s 174us/step - loss: 0.0791 - get_f1: 0.7282 - val_loss: 0.1084 - val_get_f1: 0.6649\n",
      "\n",
      "Epoch 00025: val_get_f1 did not improve from 0.66966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f0f19dc18>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=2048*2,\n",
    "          epochs=25,\n",
    "          validation_split=0.3, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2EK-Xp6EPEVR",
    "outputId": "5b09d062-ae03-46ee-a708-92b8834feb76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amsgrad': False,\n",
       " 'beta_1': 0.8999999761581421,\n",
       " 'beta_2': 0.9990000128746033,\n",
       " 'decay': 0.0,\n",
       " 'epsilon': 1e-07,\n",
       " 'lr': 0.0024999999441206455}"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pb7Oie2EE2uj"
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights-improvement.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "n8ifaRVz4Zah",
    "outputId": "b722b4d6-0121-4012-cef6-04e7b90ce5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391836/391836 [==============================] - 30s 77us/step\n",
      "Test Loss: 0.10312879059361556\n",
      "Test F1 Score: 0.6746514823591312\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_val, y_val,\n",
    "                            batch_size=2048)\n",
    "print('Test Loss:', score)\n",
    "print('Test F1 Score:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "_nm8paz2Riq2",
    "outputId": "8a83301c-8c8d-4aa0-e48a-d7e1c297eca6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSET+P790Gx8lwzE5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "FQECKDxFo5IG",
    "outputId": "33482714-6f6e-4fd9-d1bb-c3b227d64fb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWMIwxhjTKZYwjDHGdMr/D40oCJuu9yCsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['get_f1'])\n",
    "plt.plot(model.history.history['val_get_f1'])\n",
    "plt.title('Model F1')\n",
    "plt.ylabel('f1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From figure 1 the loss of the model has not changed a lot after 5 epocs on our validation set but training loss is decreased as epochs increased.\n",
    "2. From figure 2 F1 score of validation set does not change much just fluctuated between 0.64 and 0.67 but training set f1 score constantly increased upto 0.75 as number of epochs increases.\n",
    "3. From the abpve figure by looking at the f1 score after 9th epoch validation set f1 score became constant and training set f1 score increased indicating the model is overfitting.\n",
    "4. With bidirectional lstm using attention layer we are able to get 0.675 f1 score on our test set. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "QuoraInc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
